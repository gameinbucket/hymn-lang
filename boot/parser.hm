import stream
import tokens (token)
import tokenizer (tokenizer)
import parsing_errors (parse_error)
import hymnfile (hymn_file)

class parser
    file     hymn_file
    tokenize tokenizer
    tok      token
    out      string
    path     string
    pos      int
    line     int

def parse(out string, path string) maybe<parse_error>
    echo(out)
    echo(path)
    echo(system("pwd"))
    data = cat(path)
    file_stream = stream.new(data)
    tokenize = tokenizer.new(file_stream)
    tok = tokenize.get(0)
    echo(data)
    echo(tok.to_string())
    return none

def parser.next()
    self.pos += 1
    tok = self.tokenize.get(self.pos)
    if tok.type == "line" or tok.type == "comment"
        self.line += 1
    self.tok = tok

def parser.verify(expected string) bool
    if self.tok.type != expected
        return false
    return true

def parser.eat(expected string) bool
    if not self.verify(expected)
        return false
    self.next()
    return true

def parser.error(description string) parse_error
    return parse_error (
        description: description
        line: self.line
    )
